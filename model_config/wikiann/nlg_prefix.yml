batch_size: 16
gradient_accumulation_steps: 2
checkpoint_every_step: 1000
num_training_steps: 1000
tokenizer_type: t5-large
lm_type: t5-large
prefix_length: 5
prefix_set_number: 2
sample_num: 1
label_path: NLU_training_dataset/wikiner/labels.txt
dev_path: NLU_training_dataset/wikiner/valid_whole.txt
test_path: NLU_training_dataset/wikiner/test_whole.txt                              
